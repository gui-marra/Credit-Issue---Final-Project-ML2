{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/data.csv')\n",
    "Y = data['Y']\n",
    "data = data.drop(['Y'], axis = 1)\n",
    "\n",
    "\n",
    "# data = pd.read_csv('../data/data_scaled.csv')\n",
    "# Y = data['Y']\n",
    "# data = data.drop(['Unnamed: 0', 'Y'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling \n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "# ros = SMOTE(random_state=0)\n",
    "# ros = ADASYN(random_state=0)\n",
    "X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance over the training set: 1.0\n",
      "performance over the test set: 0.18888888888888886\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      1491\n",
      "           1       0.30      0.14      0.19       123\n",
      "\n",
      "    accuracy                           0.91      1614\n",
      "   macro avg       0.62      0.56      0.57      1614\n",
      "weighted avg       0.88      0.91      0.89      1614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# STEP 1 - First XGB - Highly Overfitted\n",
    "# Fiz Learning Rate and n_estimators\n",
    "\n",
    "xgb1_model = XGBClassifier( learning_rate=0.1, \n",
    "                                        n_estimators=1200,\n",
    "                                        max_depth=5,\n",
    "                                        min_child_weight=1,                         \n",
    "                                        gamma=0,\n",
    "                                        colsample_bytree=0.8,\n",
    "                                        objective ='binary:logistic',\n",
    "                                        scale_pos_weight = 1,\n",
    "                                        seed=42)\n",
    "\n",
    "\n",
    "xgb1_model.fit(X_train,y_train)\n",
    "y_predicted = xgb1_model.predict(X_test)\n",
    "y_predicted_train = xgb1_model.predict(X_train)\n",
    "\n",
    "\n",
    "print('performance over the training set: ' + str(f1_score(y_train, y_predicted_train)))\n",
    "print('performance over the test set: ' + str(f1_score(y_test, y_predicted)) + '\\n')\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data not Scaled performance\n",
    "# performance over the training set: 1.0\n",
    "# performance over the test set: 0.18888888888888886\n",
    "\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.93      0.97      0.95      1491\n",
    "#            1       0.30      0.14      0.19       123\n",
    "\n",
    "#     accuracy                           0.91      1614\n",
    "#    macro avg       0.62      0.56      0.57      1614\n",
    "# weighted avg       0.88      0.91      0.89      1614\n",
    "\n",
    "\n",
    "# DataScaled performance\n",
    "# performance over the training set: 1.0\n",
    "# performance over the test set: 0.17877094972067037\n",
    "\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.93      0.97      0.95      1491\n",
    "#            1       0.29      0.13      0.18       123\n",
    "\n",
    "#     accuracy                           0.91      1614\n",
    "#    macro avg       0.61      0.55      0.57      1614\n",
    "# weighted avg       0.88      0.91      0.89      1614"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2 - Tuning max_depth and min_child_weight\n",
    "\n",
    "param_test2 = {\n",
    "    'max_depth':range(1,7,1),\n",
    "    'min_child_weight':range(0,7,1)\n",
    "}\n",
    "\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, \n",
    "                                                  n_estimators=1200, \n",
    "                                                  max_depth=3,\n",
    "                                                  min_child_weight=4,\n",
    "                                                  gamma=0,  \n",
    "                                                  colsample_bytree=0.8,\n",
    "                                                  objective= 'binary:logistic',\n",
    "                                                  scale_pos_weight=1, \n",
    "                                                  seed=42), \n",
    "                        param_grid = param_test2, \n",
    "                        scoring='f1',\n",
    "                        n_jobs=4,\n",
    "                        iid=False, \n",
    "                        cv=5)\n",
    "\n",
    "\n",
    "gsearch2.fit(X_train, y_train)\n",
    "best_max_depth, best_min_child_weight = gsearch2.best_params_['max_depth'], gsearch2.best_params_['min_child_weight']\n",
    "gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing New Parameters\n",
    "\n",
    "xgb2_model = XGBClassifier( learning_rate=0.1, \n",
    "                                        n_estimators=1200,\n",
    "                                        max_depth=best_max_depth,\n",
    "                                        min_child_weight=best_min_child_weight,                         \n",
    "                                        gamma=0,\n",
    "                                        colsample_bytree=0.8,\n",
    "                                        objective ='binary:logistic',\n",
    "                                        scale_pos_weight = 1,\n",
    "                                        seed=42)\n",
    "\n",
    "\n",
    "xgb2_model.fit(X_train,y_train)\n",
    "y_predicted = xgb2_model.predict(X_test)\n",
    "y_predicted_train = xgb2_model.predict(X_train)\n",
    "\n",
    "\n",
    "print('performance over the training set: ' + str(f1_score(y_train, y_predicted_train)))\n",
    "print('performance over the test set: ' + str(f1_score(y_test, y_predicted)) + '\\n')\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3 - Tuning Gamma \n",
    "\n",
    "param_test3 = { \n",
    "    'gamma':[i/10.0 for i in range(0,5)] \n",
    "}\n",
    "\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, \n",
    "                                                  n_estimators=1200, \n",
    "                                                  max_depth = best_max_depth,\n",
    "                                                  min_child_weight = best_min_child_weight,\n",
    "                                                  gamma=0, \n",
    "                                                  colsample_bytree=0.8,\n",
    "                                                  objective= 'binary:logistic',\n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  seed=42), \n",
    "                        param_grid = param_test3, \n",
    "                        scoring='f1',\n",
    "                        n_jobs=4,\n",
    "                        iid=False, \n",
    "                        cv=5)\n",
    "\n",
    "gsearch3.fit(X_train, y_train)\n",
    "best_gamma = gsearch3.best_params_['gamma']\n",
    "gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing New Parameters\n",
    "\n",
    "xgb3_model = XGBClassifier( learning_rate=0.1, \n",
    "                                        n_estimators=1200,\n",
    "                                        max_depth=best_max_depth,\n",
    "                                        min_child_weight=best_min_child_weight,                         \n",
    "                                        gamma=best_gamma,\n",
    "                                        colsample_bytree=0.8,\n",
    "                                        objective = 'binary:logistic',\n",
    "                                        scale_pos_weight = 1,\n",
    "                                        seed=42)\n",
    "\n",
    "\n",
    "xgb3_model.fit(X_train,y_train)\n",
    "y_predicted = xgb3_model.predict(X_test)\n",
    "y_predicted_train = xgb3_model.predict(X_train)\n",
    "\n",
    "\n",
    "print('performance over the training set: ' + str(f1_score(y_train, y_predicted_train)))\n",
    "print('performance over the test set: ' + str(f1_score(y_test, y_predicted)) + '\\n')\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4 - Tuning colsample_bytree and subsaample\n",
    "\n",
    "param_test4 = {\n",
    "    'subsample':[i/10.0 for i in range(7,11)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(7,11)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, \n",
    "                                                  n_estimators=1200, \n",
    "                                                  max_depth = 3,\n",
    "                                                  min_child_weight = 5,\n",
    "                                                  gamma=0, \n",
    "                                                  subsample=1, \n",
    "                                                  colsample_bytree=0.8,\n",
    "                                                  objective= 'binary:logistic', \n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  seed=42), \n",
    "                        param_grid = param_test4, \n",
    "                        scoring='f1',\n",
    "                        n_jobs=4,\n",
    "                        iid=False, \n",
    "                        cv=5)\n",
    "\n",
    "gsearch4.fit(X_train, y_train)\n",
    "best_subsample, best_colsample_bytree = gsearch4.best_params_['subsample'], gsearch4.best_params_['colsample_bytree']\n",
    "gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing New Parameters\n",
    "\n",
    "xgb4_model = XGBClassifier( learning_rate=0.1, \n",
    "                                        n_estimators=1200,\n",
    "                                        max_depth=best_max_depth,\n",
    "                                        min_child_weight=best_min_child_weight,                         \n",
    "                                        gamma=best_gamma,\n",
    "                                        subsample= best_subsample,\n",
    "                                        colsample_bytree= best_colsample_bytree,\n",
    "                                        objective ='binary:logistic',\n",
    "                                        scale_pos_weight = 1,\n",
    "                                        seed=42)\n",
    "\n",
    "\n",
    "xgb4_model.fit(X_train,y_train)\n",
    "y_predicted = xgb4_model.predict(X_test)\n",
    "y_predicted_train = xgb4_model.predict(X_train)\n",
    "\n",
    "\n",
    "print('performance over the training set: ' + str(f1_score(y_train, y_predicted_train)))\n",
    "print('performance over the test set: ' + str(f1_score(y_test, y_predicted)) + '\\n')\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5 - Tuning Regularization Parameters\n",
    "# Lambda L2 Regularization\n",
    "\n",
    "param_test5 = {\n",
    "    'reg_lambda':[1e-2, 0.1, 0.5, 1, 2, 10]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, \n",
    "                                                  n_estimators=1200, \n",
    "                                                  max_depth=best_max_depth,\n",
    "                                                  min_child_weight=best_min_child_weight,                         \n",
    "                                                  gamma=best_gamma,\n",
    "                                                  subsample=best_subsample,\n",
    "                                                  colsample_bytree=best_colsample_bytree,\n",
    "                                                  reg_lambda = 2,\n",
    "                                                  objective= 'binary:logistic', \n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  seed=42), \n",
    "                        param_grid = param_test5, \n",
    "                        scoring='f1',\n",
    "                        n_jobs=4,\n",
    "                        iid=False, \n",
    "                        cv=5)\n",
    "\n",
    "gsearch5.fit(X_train, y_train)\n",
    "best_reg_lambda = gsearch5.best_params_['reg_lambda']\n",
    "gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closer Look - Lambda L2 Regularization\n",
    "\n",
    "param_test5 = {\n",
    "    'reg_lambda':[0.7*best_reg_lambda, 0.8*best_reg_lambda, best_reg_lambda, 1.5*best_reg_lambda, 3*best_reg_lambda]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, \n",
    "                                                  n_estimators=1200, \n",
    "                                                  max_depth=best_max_depth,\n",
    "                                                  min_child_weight=best_min_child_weight,                         \n",
    "                                                  gamma=best_gamma,\n",
    "                                                  subsample=best_subsample,\n",
    "                                                  colsample_bytree=best_colsample_bytree,\n",
    "                                                  reg_lambda = best_reg_lambda,\n",
    "                                                  objective= 'binary:logistic', \n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  seed=42), \n",
    "                        param_grid = param_test5, \n",
    "                        scoring='f1',\n",
    "                        n_jobs=4,\n",
    "                        iid=False, \n",
    "                        cv=5)\n",
    "\n",
    "gsearch5.fit(X_train, y_train)\n",
    "best_reg_lambda = gsearch5.best_params_['reg_lambda']\n",
    "gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even Closer Look - Lambda L2 Regularization\n",
    "\n",
    "param_test5 = {\n",
    "    'reg_lambda':[0.66*best_reg_lambda, 0.8*best_reg_lambda, best_reg_lambda, 1.5*best_reg_lambda, 3*best_reg_lambda]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, \n",
    "                                                  n_estimators=1200, \n",
    "                                                  max_depth=best_max_depth,\n",
    "                                                  min_child_weight=best_min_child_weight,                         \n",
    "                                                  gamma=best_gamma,\n",
    "                                                  subsample=best_subsample,\n",
    "                                                  colsample_bytree=best_colsample_bytree,\n",
    "                                                  reg_lambda = best_reg_lambda,\n",
    "                                                  objective= 'binary:logistic',  \n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  seed=42), \n",
    "                        param_grid = param_test5, \n",
    "                        scoring='f1',\n",
    "                        n_jobs=4,\n",
    "                        iid=False, \n",
    "                        cv=5)\n",
    "\n",
    "gsearch5.fit(X_train, y_train)\n",
    "best_reg_lambda = gsearch5.best_params_['reg_lambda']\n",
    "gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha L1 Regularization\n",
    "\n",
    "param_test5 = {\n",
    "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, \n",
    "                                                  n_estimators=1200, \n",
    "                                                  max_depth=best_max_depth,\n",
    "                                                  min_child_weight=best_min_child_weight,                         \n",
    "                                                  gamma=best_gamma,\n",
    "                                                  subsample=best_subsample,\n",
    "                                                  colsample_bytree=best_colsample_bytree,\n",
    "                                                  reg_lambda = best_reg_lambda,\n",
    "                                                  objective= 'binary:logistic', \n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  seed=42), \n",
    "                        param_grid = param_test5, \n",
    "                        scoring='f1',\n",
    "                        n_jobs=4,\n",
    "                        iid=False, \n",
    "                        cv=5)\n",
    "\n",
    "gsearch5.fit(X_train, y_train)\n",
    "best_reg_alpha = gsearch5.best_params_['reg_alpha']\n",
    "gsearch5.best_params_, gsearch5.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6 - Reducing Learning Rate and Adding More Trees\n",
    "\n",
    "param_test6 = {\n",
    "    'learning_rate':[i/100.0 for i in range(5,20,2)]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, \n",
    "                                                  n_estimators=3000, \n",
    "                                                  max_depth=best_max_depth,\n",
    "                                                  min_child_weight=best_min_child_weight,                         \n",
    "                                                  gamma=best_gamma,\n",
    "                                                  subsample=best_subsample,\n",
    "                                                  colsample_bytree=best_colsample_bytree,\n",
    "                                                  reg_lambda=best_reg_lambda,\n",
    "                                                  reg_alpha=best_reg_alpha,\n",
    "                                                  objective= 'binary:logistic', \n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  seed=42), \n",
    "                        param_grid = param_test6, \n",
    "                        scoring='f1',\n",
    "                        n_jobs=4,\n",
    "                        iid=False, \n",
    "                        cv=5)\n",
    "\n",
    "gsearch6.fit(X_train, y_train)\n",
    "best_LR = gsearch6.best_params_['learning_rate']\n",
    "gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Evaluation\n",
    "\n",
    "\n",
    "xgb6_model = XGBClassifier(learning_rate=best_LR, \n",
    "                                        n_estimators=3000,\n",
    "                                        max_depth=best_max_depth,\n",
    "                                        min_child_weight=best_min_child_weight,                         \n",
    "                                        gamma=best_gamma,\n",
    "                                        subsample=best_subsample,\n",
    "                                        colsample_bytree=best_colsample_bytree,\n",
    "                                        reg_lambda=best_reg_lambda,\n",
    "                                        reg_alpha=best_reg_alpha,\n",
    "                                        objective= 'binary:logistic', \n",
    "                                        scale_pos_weight = 1,\n",
    "                                        seed=42)\n",
    "\n",
    "\n",
    "xgb6_model.fit(X_train,y_train)\n",
    "y_predicted = xgb6_model.predict(X_test)\n",
    "y_predicted_train = xgb6_model.predict(X_train)\n",
    "\n",
    "\n",
    "print('performance over the training set: ' + str(f1_score(y_train, y_predicted_train)))\n",
    "print('performance over the test set: ' + str(f1_score(y_test, y_predicted)) + '\\n')\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance over the training set: 0.9937464468447982\n",
      "performance over the test set: 0.2375478927203065\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93      1491\n",
      "           1       0.22      0.25      0.24       123\n",
      "\n",
      "    accuracy                           0.88      1614\n",
      "   macro avg       0.58      0.59      0.59      1614\n",
      "weighted avg       0.88      0.88      0.88      1614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Final Evaluation\n",
    "\n",
    "\n",
    "xgb6_model = XGBClassifier(learning_rate=0.07, \n",
    "                                        n_estimators=2000,\n",
    "                                        max_depth=3,\n",
    "                                        min_child_weight=5,                         \n",
    "                                        gamma=0,\n",
    "                                        subsample=1,\n",
    "                                        colsample_bytree=0.8,\n",
    "                                        reg_alpha=0,\n",
    "                                        reg_lambda=3,\n",
    "                                        objective ='binary:logistic',\n",
    "                                        scale_pos_weight = 1,\n",
    "                                        seed=42)\n",
    "\n",
    "\n",
    "xgb6_model.fit(X_train,y_train)\n",
    "y_predicted = xgb6_model.predict(X_test)\n",
    "y_predicted_train = xgb6_model.predict(X_train)\n",
    "\n",
    "\n",
    "print('performance over the training set: ' + str(f1_score(y_train, y_predicted_train)))\n",
    "print('performance over the test set: ' + str(f1_score(y_test, y_predicted)) + '\\n')\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_Of_Dependant</th>\n",
       "      <th>Years_At_Residence</th>\n",
       "      <th>Years_At_Business</th>\n",
       "      <th>Nb_Of_Products</th>\n",
       "      <th>DAY(BirthDate)</th>\n",
       "      <th>DAY(Customer_Open_Date)</th>\n",
       "      <th>DAY(Prod_Decision_Date)</th>\n",
       "      <th>YEAR(BirthDate)</th>\n",
       "      <th>YEAR(Customer_Open_Date)</th>\n",
       "      <th>YEAR(Prod_Decision_Date)</th>\n",
       "      <th>...</th>\n",
       "      <th>Prod_Category_I</th>\n",
       "      <th>Prod_Category_J</th>\n",
       "      <th>Prod_Category_K</th>\n",
       "      <th>Prod_Category_L</th>\n",
       "      <th>Prod_Category_M</th>\n",
       "      <th>KMeans 2</th>\n",
       "      <th>KMeans 3</th>\n",
       "      <th>Agglomerative Clustering Cosine</th>\n",
       "      <th>Agglomerative Clustering Euclidean</th>\n",
       "      <th>DBSCAN eps=3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.703491</td>\n",
       "      <td>2.243852</td>\n",
       "      <td>-0.451898</td>\n",
       "      <td>-0.299213</td>\n",
       "      <td>1.637976</td>\n",
       "      <td>0.280783</td>\n",
       "      <td>1.080961</td>\n",
       "      <td>-0.433226</td>\n",
       "      <td>0.284388</td>\n",
       "      <td>-0.770762</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027277</td>\n",
       "      <td>-0.115644</td>\n",
       "      <td>-0.227615</td>\n",
       "      <td>-0.214193</td>\n",
       "      <td>-0.095872</td>\n",
       "      <td>0.633855</td>\n",
       "      <td>0.622740</td>\n",
       "      <td>0.802342</td>\n",
       "      <td>0.301022</td>\n",
       "      <td>-0.193059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.790403</td>\n",
       "      <td>0.739525</td>\n",
       "      <td>-0.451898</td>\n",
       "      <td>3.061464</td>\n",
       "      <td>-0.916956</td>\n",
       "      <td>0.280783</td>\n",
       "      <td>0.485969</td>\n",
       "      <td>-1.892971</td>\n",
       "      <td>0.284388</td>\n",
       "      <td>-0.770762</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027277</td>\n",
       "      <td>-0.115644</td>\n",
       "      <td>-0.227615</td>\n",
       "      <td>-0.214193</td>\n",
       "      <td>-0.095872</td>\n",
       "      <td>0.633855</td>\n",
       "      <td>-1.788445</td>\n",
       "      <td>-1.246352</td>\n",
       "      <td>0.301022</td>\n",
       "      <td>-0.486433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.790403</td>\n",
       "      <td>0.238083</td>\n",
       "      <td>-0.451898</td>\n",
       "      <td>3.061464</td>\n",
       "      <td>0.244376</td>\n",
       "      <td>0.761181</td>\n",
       "      <td>0.723966</td>\n",
       "      <td>0.661583</td>\n",
       "      <td>0.284388</td>\n",
       "      <td>-0.770762</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027277</td>\n",
       "      <td>-0.115644</td>\n",
       "      <td>-0.227615</td>\n",
       "      <td>-0.214193</td>\n",
       "      <td>-0.095872</td>\n",
       "      <td>0.633855</td>\n",
       "      <td>0.622740</td>\n",
       "      <td>0.802342</td>\n",
       "      <td>0.301022</td>\n",
       "      <td>-0.125357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.703491</td>\n",
       "      <td>-0.062783</td>\n",
       "      <td>-0.313478</td>\n",
       "      <td>-0.299213</td>\n",
       "      <td>0.825043</td>\n",
       "      <td>-0.079516</td>\n",
       "      <td>0.009976</td>\n",
       "      <td>0.296646</td>\n",
       "      <td>0.603939</td>\n",
       "      <td>1.297417</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027277</td>\n",
       "      <td>-0.115644</td>\n",
       "      <td>-0.227615</td>\n",
       "      <td>-0.214193</td>\n",
       "      <td>-0.095872</td>\n",
       "      <td>0.633855</td>\n",
       "      <td>0.622740</td>\n",
       "      <td>0.802342</td>\n",
       "      <td>0.301022</td>\n",
       "      <td>-0.193059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.450438</td>\n",
       "      <td>4.149332</td>\n",
       "      <td>3.285447</td>\n",
       "      <td>3.061464</td>\n",
       "      <td>-0.800823</td>\n",
       "      <td>0.040584</td>\n",
       "      <td>-0.228021</td>\n",
       "      <td>-1.436801</td>\n",
       "      <td>-0.354713</td>\n",
       "      <td>-0.770762</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027277</td>\n",
       "      <td>-0.115644</td>\n",
       "      <td>-0.227615</td>\n",
       "      <td>-0.214193</td>\n",
       "      <td>-0.095872</td>\n",
       "      <td>0.633855</td>\n",
       "      <td>0.622740</td>\n",
       "      <td>0.802342</td>\n",
       "      <td>0.301022</td>\n",
       "      <td>-0.486433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6987</td>\n",
       "      <td>-0.790403</td>\n",
       "      <td>1.240967</td>\n",
       "      <td>-0.313478</td>\n",
       "      <td>-0.299213</td>\n",
       "      <td>1.405709</td>\n",
       "      <td>1.721978</td>\n",
       "      <td>-1.537003</td>\n",
       "      <td>1.482689</td>\n",
       "      <td>0.284388</td>\n",
       "      <td>-0.770762</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027277</td>\n",
       "      <td>-0.115644</td>\n",
       "      <td>-0.227615</td>\n",
       "      <td>-0.214193</td>\n",
       "      <td>-0.095872</td>\n",
       "      <td>0.633855</td>\n",
       "      <td>0.622740</td>\n",
       "      <td>0.802342</td>\n",
       "      <td>0.301022</td>\n",
       "      <td>-0.486433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6988</td>\n",
       "      <td>-0.790403</td>\n",
       "      <td>0.438659</td>\n",
       "      <td>1.209144</td>\n",
       "      <td>-0.299213</td>\n",
       "      <td>0.128243</td>\n",
       "      <td>-1.640811</td>\n",
       "      <td>-1.537003</td>\n",
       "      <td>0.114178</td>\n",
       "      <td>0.284388</td>\n",
       "      <td>-0.770762</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027277</td>\n",
       "      <td>-0.115644</td>\n",
       "      <td>-0.227615</td>\n",
       "      <td>-0.214193</td>\n",
       "      <td>10.430528</td>\n",
       "      <td>-1.577649</td>\n",
       "      <td>-1.788445</td>\n",
       "      <td>-1.246352</td>\n",
       "      <td>0.301022</td>\n",
       "      <td>-0.486433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6989</td>\n",
       "      <td>-0.790403</td>\n",
       "      <td>0.438659</td>\n",
       "      <td>1.209144</td>\n",
       "      <td>-0.299213</td>\n",
       "      <td>0.128243</td>\n",
       "      <td>-1.640811</td>\n",
       "      <td>-1.537003</td>\n",
       "      <td>0.114178</td>\n",
       "      <td>0.284388</td>\n",
       "      <td>-0.770762</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027277</td>\n",
       "      <td>-0.115644</td>\n",
       "      <td>-0.227615</td>\n",
       "      <td>-0.214193</td>\n",
       "      <td>10.430528</td>\n",
       "      <td>-1.577649</td>\n",
       "      <td>-1.788445</td>\n",
       "      <td>-1.246352</td>\n",
       "      <td>0.301022</td>\n",
       "      <td>-0.486433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6990</td>\n",
       "      <td>-0.790403</td>\n",
       "      <td>0.238083</td>\n",
       "      <td>-0.451898</td>\n",
       "      <td>-0.299213</td>\n",
       "      <td>-0.916956</td>\n",
       "      <td>1.241580</td>\n",
       "      <td>-0.109023</td>\n",
       "      <td>1.391455</td>\n",
       "      <td>0.284388</td>\n",
       "      <td>-0.770762</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027277</td>\n",
       "      <td>-0.115644</td>\n",
       "      <td>-0.227615</td>\n",
       "      <td>4.668684</td>\n",
       "      <td>-0.095872</td>\n",
       "      <td>0.633855</td>\n",
       "      <td>0.622740</td>\n",
       "      <td>0.802342</td>\n",
       "      <td>0.301022</td>\n",
       "      <td>-0.035088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6991</td>\n",
       "      <td>-0.043456</td>\n",
       "      <td>0.739525</td>\n",
       "      <td>-0.313478</td>\n",
       "      <td>-0.299213</td>\n",
       "      <td>0.592776</td>\n",
       "      <td>-0.800113</td>\n",
       "      <td>-0.823013</td>\n",
       "      <td>0.661583</td>\n",
       "      <td>-0.035162</td>\n",
       "      <td>-0.770762</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027277</td>\n",
       "      <td>-0.115644</td>\n",
       "      <td>-0.227615</td>\n",
       "      <td>-0.214193</td>\n",
       "      <td>-0.095872</td>\n",
       "      <td>-1.577649</td>\n",
       "      <td>-0.582853</td>\n",
       "      <td>-1.246352</td>\n",
       "      <td>-3.322017</td>\n",
       "      <td>1.476917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6992 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Number_Of_Dependant  Years_At_Residence  Years_At_Business  \\\n",
       "0                0.703491            2.243852          -0.451898   \n",
       "1               -0.790403            0.739525          -0.451898   \n",
       "2               -0.790403            0.238083          -0.451898   \n",
       "3                0.703491           -0.062783          -0.313478   \n",
       "4                1.450438            4.149332           3.285447   \n",
       "...                   ...                 ...                ...   \n",
       "6987            -0.790403            1.240967          -0.313478   \n",
       "6988            -0.790403            0.438659           1.209144   \n",
       "6989            -0.790403            0.438659           1.209144   \n",
       "6990            -0.790403            0.238083          -0.451898   \n",
       "6991            -0.043456            0.739525          -0.313478   \n",
       "\n",
       "      Nb_Of_Products  DAY(BirthDate)  DAY(Customer_Open_Date)  \\\n",
       "0          -0.299213        1.637976                 0.280783   \n",
       "1           3.061464       -0.916956                 0.280783   \n",
       "2           3.061464        0.244376                 0.761181   \n",
       "3          -0.299213        0.825043                -0.079516   \n",
       "4           3.061464       -0.800823                 0.040584   \n",
       "...              ...             ...                      ...   \n",
       "6987       -0.299213        1.405709                 1.721978   \n",
       "6988       -0.299213        0.128243                -1.640811   \n",
       "6989       -0.299213        0.128243                -1.640811   \n",
       "6990       -0.299213       -0.916956                 1.241580   \n",
       "6991       -0.299213        0.592776                -0.800113   \n",
       "\n",
       "      DAY(Prod_Decision_Date)  YEAR(BirthDate)  YEAR(Customer_Open_Date)  \\\n",
       "0                    1.080961        -0.433226                  0.284388   \n",
       "1                    0.485969        -1.892971                  0.284388   \n",
       "2                    0.723966         0.661583                  0.284388   \n",
       "3                    0.009976         0.296646                  0.603939   \n",
       "4                   -0.228021        -1.436801                 -0.354713   \n",
       "...                       ...              ...                       ...   \n",
       "6987                -1.537003         1.482689                  0.284388   \n",
       "6988                -1.537003         0.114178                  0.284388   \n",
       "6989                -1.537003         0.114178                  0.284388   \n",
       "6990                -0.109023         1.391455                  0.284388   \n",
       "6991                -0.823013         0.661583                 -0.035162   \n",
       "\n",
       "      YEAR(Prod_Decision_Date)  ...  Prod_Category_I  Prod_Category_J  \\\n",
       "0                    -0.770762  ...        -0.027277        -0.115644   \n",
       "1                    -0.770762  ...        -0.027277        -0.115644   \n",
       "2                    -0.770762  ...        -0.027277        -0.115644   \n",
       "3                     1.297417  ...        -0.027277        -0.115644   \n",
       "4                    -0.770762  ...        -0.027277        -0.115644   \n",
       "...                        ...  ...              ...              ...   \n",
       "6987                 -0.770762  ...        -0.027277        -0.115644   \n",
       "6988                 -0.770762  ...        -0.027277        -0.115644   \n",
       "6989                 -0.770762  ...        -0.027277        -0.115644   \n",
       "6990                 -0.770762  ...        -0.027277        -0.115644   \n",
       "6991                 -0.770762  ...        -0.027277        -0.115644   \n",
       "\n",
       "      Prod_Category_K  Prod_Category_L  Prod_Category_M  KMeans 2  KMeans 3  \\\n",
       "0           -0.227615        -0.214193        -0.095872  0.633855  0.622740   \n",
       "1           -0.227615        -0.214193        -0.095872  0.633855 -1.788445   \n",
       "2           -0.227615        -0.214193        -0.095872  0.633855  0.622740   \n",
       "3           -0.227615        -0.214193        -0.095872  0.633855  0.622740   \n",
       "4           -0.227615        -0.214193        -0.095872  0.633855  0.622740   \n",
       "...               ...              ...              ...       ...       ...   \n",
       "6987        -0.227615        -0.214193        -0.095872  0.633855  0.622740   \n",
       "6988        -0.227615        -0.214193        10.430528 -1.577649 -1.788445   \n",
       "6989        -0.227615        -0.214193        10.430528 -1.577649 -1.788445   \n",
       "6990        -0.227615         4.668684        -0.095872  0.633855  0.622740   \n",
       "6991        -0.227615        -0.214193        -0.095872 -1.577649 -0.582853   \n",
       "\n",
       "      Agglomerative Clustering Cosine  Agglomerative Clustering Euclidean  \\\n",
       "0                            0.802342                            0.301022   \n",
       "1                           -1.246352                            0.301022   \n",
       "2                            0.802342                            0.301022   \n",
       "3                            0.802342                            0.301022   \n",
       "4                            0.802342                            0.301022   \n",
       "...                               ...                                 ...   \n",
       "6987                         0.802342                            0.301022   \n",
       "6988                        -1.246352                            0.301022   \n",
       "6989                        -1.246352                            0.301022   \n",
       "6990                         0.802342                            0.301022   \n",
       "6991                        -1.246352                           -3.322017   \n",
       "\n",
       "      DBSCAN eps=3  \n",
       "0        -0.193059  \n",
       "1        -0.486433  \n",
       "2        -0.125357  \n",
       "3        -0.193059  \n",
       "4        -0.486433  \n",
       "...            ...  \n",
       "6987     -0.486433  \n",
       "6988     -0.486433  \n",
       "6989     -0.486433  \n",
       "6990     -0.035088  \n",
       "6991      1.476917  \n",
       "\n",
       "[6992 rows x 58 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data not scaled\n",
    "# performance over the training set: 0.9937464468447982\n",
    "# performance over the test set: 0.2375478927203065\n",
    "\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.94      0.93      0.93      1491\n",
    "#            1       0.22      0.25      0.24       123\n",
    "\n",
    "#     accuracy                           0.88      1614\n",
    "#    macro avg       0.58      0.59      0.59      1614\n",
    "# weighted avg       0.88      0.88      0.88      1614\n",
    "\n",
    "\n",
    "# data_scaled\n",
    "# performance over the training set: 0.9937464468447982\n",
    "# performance over the test set: 0.2375478927203065\n",
    "\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.94      0.93      0.93      1491\n",
    "#            1       0.22      0.25      0.24       123\n",
    "\n",
    "#     accuracy                           0.88      1614\n",
    "#    macro avg       0.58      0.59      0.59      1614\n",
    "# weighted avg       0.88      0.88      0.88      1614"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
